{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first XGboost model\n",
    "\n",
    "Here I train and tune an XGboost model on the first set of features I've extracted. These features are very basic, and don't involve any great insight, so I don't expect the results to be competitive. This notebook mainly serves as a baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "\n",
    "Loading the training and test data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"../data/first_features/X.npy\")\n",
    "y = np.load(\"../data/first_features/y.npy\")\n",
    "X_test =  np.load(\"../data/first_features/X_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 107)\n",
      "(1503424,)\n",
      "(508438, 107)\n"
     ]
    }
   ],
   "source": [
    "# sanity check - do the shapes line up? \n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can change the type of these matrices to save some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286930944"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.nbytes # 1.2 gig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643465472"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.astype(np.float32).nbytes #.64 gig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up train/validation splits\n",
    "\n",
    "For the purpose of hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of actually splitting up the data `X` into seperate training and vaidation splits, I'll just save the indecies of the training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_idx = np.repeat(-1, y.shape)\n",
    "np.random.seed(109)\n",
    "validation_idx[np.random.choice(validation_idx.shape[0], \n",
    "       int(round(.15*validation_idx.shape[0])), replace = False)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225514\n",
      "0.15000026605934189\n"
     ]
    }
   ],
   "source": [
    "# now, we have an integer vector, where `-1` is training, and `0` is validation\n",
    "print(np.sum(validation_idx == 0))\n",
    "print(np.mean(validation_idx == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Approximate model complexity\n",
    "\n",
    "The first thing I'll do is get a feel for how complex a model I should be using. to do this, I'll define a grid with the parameters `n_estimators` and `max_depth` with very large intervals - to get a feel for the order of magnitude I should be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1 = {\"n_estimators\" : [100, 500, 1500], \n",
    "        \"max_depth\" : [6, 18, 36]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a predefined validation split to be based to a `GridSearchCV` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = list(PredefinedSplit(validation_idx).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = XGBRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = GridSearchCV(model1, grid1,\n",
    "           n_jobs=-1, \n",
    "           cv=2,\n",
    "           verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV] max_depth=6, n_estimators=500 ...................................\n",
      "[CV] max_depth=6, n_estimators=500 ...................................\n",
      "[CV]  max_depth=6, n_estimators=100, score=0.21739099778745896, total=19.3min\n",
      "[CV] max_depth=6, n_estimators=1500 ..................................\n",
      "[CV]  max_depth=6, n_estimators=100, score=0.21887805484771763, total=19.5min\n",
      "[CV] max_depth=6, n_estimators=1500 ..................................\n",
      "[CV]  max_depth=6, n_estimators=500, score=0.24357616017622352, total=89.2min\n",
      "[CV] max_depth=18, n_estimators=100 ..................................\n",
      "[CV]  max_depth=6, n_estimators=500, score=0.2458863049923381, total=89.8min\n",
      "[CV] max_depth=18, n_estimators=100 ..................................\n",
      "[CV]  max_depth=18, n_estimators=100, score=0.22546651606542642, total=54.4min\n",
      "[CV] max_depth=18, n_estimators=500 ..................................\n",
      "[CV]  max_depth=18, n_estimators=100, score=0.2274598849497063, total=54.6min\n",
      "[CV] max_depth=18, n_estimators=500 ..................................\n",
      "[CV]  max_depth=6, n_estimators=1500, score=0.25592675148305544, total=219.0min\n",
      "[CV]  max_depth=6, n_estimators=1500, score=0.2528493741977641, total=219.3min\n",
      "[CV] max_depth=18, n_estimators=1500 .................................\n",
      "[CV] max_depth=18, n_estimators=1500 .................................\n",
      "[CV]  max_depth=18, n_estimators=500, score=0.2095684286267513, total=258.0min\n",
      "[CV] max_depth=36, n_estimators=100 ..................................\n",
      "[CV]  max_depth=18, n_estimators=500, score=0.20556441403957296, total=259.7min\n",
      "[CV] max_depth=36, n_estimators=100 ..................................\n",
      "[CV]  max_depth=36, n_estimators=100, score=0.1599381262995293, total=159.1min\n",
      "[CV] max_depth=36, n_estimators=500 ..................................\n",
      "[CV]  max_depth=36, n_estimators=100, score=0.16384914476550036, total=159.6min\n",
      "[CV] max_depth=36, n_estimators=500 ..................................\n",
      "[CV]  max_depth=36, n_estimators=500, score=0.16375084842311827, total=230.5min\n",
      "[CV] max_depth=36, n_estimators=1500 .................................\n",
      "[CV]  max_depth=36, n_estimators=500, score=0.1598386453806514, total=235.9min\n",
      "[CV] max_depth=36, n_estimators=1500 .................................\n",
      "[CV]  max_depth=18, n_estimators=1500, score=0.19993742518838267, total=735.7min\n",
      "[CV]  max_depth=18, n_estimators=1500, score=0.19636477047073586, total=740.4min\n",
      "[CV]  max_depth=36, n_estimators=1500, score=0.16375084842311827, total=227.0min\n",
      "[CV]  max_depth=36, n_estimators=1500, score=0.1598386453806514, total=232.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed: 1054.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed: 1054.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 26min 52s, sys: 35.7 s, total: 3h 27min 27s\n",
      "Wall time: 20h 59min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 500, 1500], 'max_depth': [6, 18, 36]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time gs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'n_estimators': 1500}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25438806284040977"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
